<Train---------------> [20230722-084733] [INFO]: Waiting for environment to fill memory...
<Train---------------> [20230722-084741] [INFO]: Training Start...
<Train---------------> [20230722-084743] [INFO]: Iteration 0, loss: -0.010080739855766296, avg_reward: -0.00043090491089969873, memory_size: 64, batch_size: 1
<Train---------------> [20230722-084743] [INFO]: Model saved to Checkpoints/20230722-084728//model_it0.pth at iteration 0
<Train---------------> [20230722-084829] [INFO]: Iteration 500, loss: -0.014291937462985516, avg_reward: 0.022998761385679245, memory_size: 558, batch_size: 64
<Train---------------> [20230722-084926] [INFO]: Iteration 1000, loss: -0.0077875349670648575, avg_reward: 0.0019879930187016726, memory_size: 1165, batch_size: 64
<Train---------------> [20230722-084926] [INFO]: Model saved to Checkpoints/20230722-084728//model_it1000.pth at iteration 1000
<Train---------------> [20230722-085023] [INFO]: Iteration 1500, loss: -0.01004761178046465, avg_reward: -0.33992427587509155, memory_size: 1791, batch_size: 64
<Train---------------> [20230722-085042] [INFO]: Saving memory...
<Train---------------> [20230722-085119] [INFO]: Iteration 2000, loss: -0.017575299367308617, avg_reward: -1.0370094776153564, memory_size: 2370, batch_size: 64
<Train---------------> [20230722-085119] [INFO]: Model saved to Checkpoints/20230722-084728//model_it2000.pth at iteration 2000
<Train---------------> [20230722-085211] [INFO]: Iteration 2500, loss: -0.007513440679758787, avg_reward: 0.0589919313788414, memory_size: 2937, batch_size: 64
<Train---------------> [20230722-085306] [INFO]: Iteration 3000, loss: -0.016770781949162483, avg_reward: -0.4660915434360504, memory_size: 3512, batch_size: 64
<Train---------------> [20230722-085306] [INFO]: Model saved to Checkpoints/20230722-084728//model_it3000.pth at iteration 3000
<Train---------------> [20230722-085350] [INFO]: Saving memory...
<Train---------------> [20230722-085400] [INFO]: Iteration 3500, loss: -0.01129799336194992, avg_reward: -0.6756750345230103, memory_size: 4123, batch_size: 64
<Train---------------> [20230722-085454] [INFO]: Iteration 4000, loss: -0.03179201856255531, avg_reward: 0.016548575833439827, memory_size: 4793, batch_size: 64
<Train---------------> [20230722-085454] [INFO]: Model saved to Checkpoints/20230722-084728//model_it4000.pth at iteration 4000
<Train---------------> [20230722-085548] [INFO]: Iteration 4500, loss: -0.05149989202618599, avg_reward: -0.5384029150009155, memory_size: 5458, batch_size: 64
<Train---------------> [20230722-085630] [INFO]: Saving memory...
<Train---------------> [20230722-085645] [INFO]: Iteration 5000, loss: -0.06615982204675674, avg_reward: 0.015469803474843502, memory_size: 6179, batch_size: 64
<Train---------------> [20230722-085645] [INFO]: Model saved to Checkpoints/20230722-084728//model_it5000.pth at iteration 5000
<Train---------------> [20230722-085738] [INFO]: Iteration 5500, loss: -0.06319484859704971, avg_reward: 0.008242589421570301, memory_size: 6803, batch_size: 64
<Train---------------> [20230722-085832] [INFO]: Iteration 6000, loss: -0.020935503765940666, avg_reward: -0.04173043370246887, memory_size: 7368, batch_size: 64
<Train---------------> [20230722-085832] [INFO]: Model saved to Checkpoints/20230722-084728//model_it6000.pth at iteration 6000
<Train---------------> [20230722-085926] [INFO]: Iteration 6500, loss: -0.045069560408592224, avg_reward: -0.15912455320358276, memory_size: 7919, batch_size: 64
<Train---------------> [20230722-085934] [INFO]: Saving memory...
<Train---------------> [20230722-090023] [INFO]: Iteration 7000, loss: -0.030951254069805145, avg_reward: 3.1855470297159627e-06, memory_size: 8000, batch_size: 64
<Train---------------> [20230722-090023] [INFO]: Model saved to Checkpoints/20230722-084728//model_it7000.pth at iteration 7000
<Train---------------> [20230722-090119] [INFO]: Iteration 7500, loss: -0.013094098307192326, avg_reward: 0.003848475404083729, memory_size: 8000, batch_size: 64
<Train---------------> [20230722-090212] [INFO]: Iteration 8000, loss: -0.029795007780194283, avg_reward: -0.002039742423221469, memory_size: 8000, batch_size: 64
<Train---------------> [20230722-090212] [INFO]: Model saved to Checkpoints/20230722-084728//model_it8000.pth at iteration 8000
<Train---------------> [20230722-090246] [INFO]: Saving memory...
<Train---------------> [20230722-090310] [INFO]: Iteration 8500, loss: -0.0007156303618103266, avg_reward: -1.0599141120910645, memory_size: 8000, batch_size: 64
<Train---------------> [20230722-090406] [INFO]: Iteration 9000, loss: -0.030343880876898766, avg_reward: 0.01791101135313511, memory_size: 8000, batch_size: 64
<Train---------------> [20230722-090406] [INFO]: Model saved to Checkpoints/20230722-084728//model_it9000.pth at iteration 9000
<Train---------------> [20230722-090458] [INFO]: Iteration 9500, loss: -0.03738958761096001, avg_reward: -0.11003956943750381, memory_size: 8000, batch_size: 64
<Train---------------> [20230722-090553] [INFO]: Iteration 10000, loss: -0.004333861637860537, avg_reward: -0.6810302138328552, memory_size: 8000, batch_size: 64
<Train---------------> [20230722-090553] [INFO]: Model saved to Checkpoints/20230722-084728//model_it10000.pth at iteration 10000
<Train---------------> [20230722-090558] [INFO]: Saving memory...
<Train---------------> [20230722-090651] [INFO]: Iteration 10500, loss: 0.016656115651130676, avg_reward: 0.01950383186340332, memory_size: 8000, batch_size: 64
<Train---------------> [20230722-090747] [INFO]: Iteration 11000, loss: -0.015740439295768738, avg_reward: 0.010523262433707714, memory_size: 8000, batch_size: 64
<Train---------------> [20230722-090747] [INFO]: Model saved to Checkpoints/20230722-084728//model_it11000.pth at iteration 11000
<Train---------------> [20230722-090847] [INFO]: Iteration 11500, loss: -0.00766443507745862, avg_reward: 0.003643050557002425, memory_size: 8000, batch_size: 64
<Train---------------> [20230722-090911] [INFO]: Saving memory...
<Train---------------> [20230722-090943] [INFO]: Iteration 12000, loss: -0.01032545417547226, avg_reward: -1.320479154586792, memory_size: 8000, batch_size: 64
<Train---------------> [20230722-090943] [INFO]: Model saved to Checkpoints/20230722-084728//model_it12000.pth at iteration 12000
<Train---------------> [20230722-091039] [INFO]: Iteration 12500, loss: -0.02376306615769863, avg_reward: -0.0004898154875263572, memory_size: 8000, batch_size: 64
<Train---------------> [20230722-091133] [INFO]: Iteration 13000, loss: -0.0272374227643013, avg_reward: -0.0007023096550256014, memory_size: 8000, batch_size: 64
<Train---------------> [20230722-091133] [INFO]: Model saved to Checkpoints/20230722-084728//model_it13000.pth at iteration 13000
<Train---------------> [20230722-091219] [INFO]: Saving memory...
<Train---------------> [20230722-091230] [INFO]: Iteration 13500, loss: -0.015059428289532661, avg_reward: 3.520708924042992e-05, memory_size: 8000, batch_size: 64
<Train---------------> [20230722-091325] [INFO]: Iteration 14000, loss: -0.019594406709074974, avg_reward: -0.001445674803107977, memory_size: 8000, batch_size: 64
<Train---------------> [20230722-091325] [INFO]: Model saved to Checkpoints/20230722-084728//model_it14000.pth at iteration 14000
<Train---------------> [20230722-091419] [INFO]: Iteration 14500, loss: -0.01941884681582451, avg_reward: -0.0012299066875129938, memory_size: 8000, batch_size: 64
<Train---------------> [20230722-091513] [INFO]: Iteration 15000, loss: -0.023037388920783997, avg_reward: 0.00011375993199180812, memory_size: 8000, batch_size: 64
<Train---------------> [20230722-091513] [INFO]: Model saved to Checkpoints/20230722-084728//model_it15000.pth at iteration 15000
<Train---------------> [20230722-091529] [INFO]: Saving memory...
<Train---------------> [20230722-091613] [INFO]: Iteration 15500, loss: 0.02858070284128189, avg_reward: 0.010895941406488419, memory_size: 8000, batch_size: 64
<Train---------------> [20230722-091709] [INFO]: Iteration 16000, loss: -0.032047469168901443, avg_reward: 0.0031030839309096336, memory_size: 8000, batch_size: 64
<Train---------------> [20230722-091709] [INFO]: Model saved to Checkpoints/20230722-084728//model_it16000.pth at iteration 16000
<Train---------------> [20230722-091805] [INFO]: Iteration 16500, loss: -0.01150226965546608, avg_reward: -0.3004983067512512, memory_size: 8000, batch_size: 64
<Train---------------> [20230722-091842] [INFO]: Saving memory...
<Train---------------> [20230722-091903] [INFO]: Iteration 17000, loss: 0.005195529665797949, avg_reward: -0.42693856358528137, memory_size: 8000, batch_size: 64
<Train---------------> [20230722-091903] [INFO]: Model saved to Checkpoints/20230722-084728//model_it17000.pth at iteration 17000
<Train---------------> [20230722-091957] [INFO]: Iteration 17500, loss: -0.012236002832651138, avg_reward: -0.08053674548864365, memory_size: 8000, batch_size: 64
<Train---------------> [20230722-092051] [INFO]: Iteration 18000, loss: -0.02945469319820404, avg_reward: 0.00030019856058061123, memory_size: 8000, batch_size: 64
<Train---------------> [20230722-092051] [INFO]: Model saved to Checkpoints/20230722-084728//model_it18000.pth at iteration 18000
<Train---------------> [20230722-092145] [INFO]: Iteration 18500, loss: 0.004195174667984247, avg_reward: -1.9033081531524658, memory_size: 8000, batch_size: 64
<Train---------------> [20230722-092148] [INFO]: Saving memory...
<Train---------------> [20230722-092242] [INFO]: Iteration 19000, loss: 0.004582961089909077, avg_reward: 8.603176684118807e-05, memory_size: 8000, batch_size: 64
<Train---------------> [20230722-092242] [INFO]: Model saved to Checkpoints/20230722-084728//model_it19000.pth at iteration 19000
<Train---------------> [20230722-092338] [INFO]: Iteration 19500, loss: -0.0007247262983582914, avg_reward: 0.034887947142124176, memory_size: 8000, batch_size: 64
<Train---------------> [20230722-092435] [INFO]: Iteration 20000, loss: -0.009300816804170609, avg_reward: -0.41128358244895935, memory_size: 8000, batch_size: 64
<Train---------------> [20230722-092435] [INFO]: Model saved to Checkpoints/20230722-084728//model_it20000.pth at iteration 20000
<Train---------------> [20230722-092456] [INFO]: Saving memory...
<Train---------------> [20230722-092534] [INFO]: Iteration 20500, loss: 0.021372217684984207, avg_reward: -0.12365708500146866, memory_size: 8000, batch_size: 64
<Train---------------> [20230722-092633] [INFO]: Iteration 21000, loss: 0.04872665926814079, avg_reward: -1.4004411697387695, memory_size: 8000, batch_size: 64
<Train---------------> [20230722-092633] [INFO]: Model saved to Checkpoints/20230722-084728//model_it21000.pth at iteration 21000
<Train---------------> [20230722-092726] [INFO]: Iteration 21500, loss: -0.01014136802405119, avg_reward: -0.019577782601118088, memory_size: 8000, batch_size: 64
<Train---------------> [20230722-092804] [INFO]: Saving memory...
<Train---------------> [20230722-092822] [INFO]: Iteration 22000, loss: 0.0055550457909703255, avg_reward: -0.2798973321914673, memory_size: 8000, batch_size: 64
<Train---------------> [20230722-092822] [INFO]: Model saved to Checkpoints/20230722-084728//model_it22000.pth at iteration 22000
<Train---------------> [20230722-092917] [INFO]: Iteration 22500, loss: 0.0009469522628933191, avg_reward: -0.6228460073471069, memory_size: 8000, batch_size: 64
<Train---------------> [20230722-093016] [INFO]: Iteration 23000, loss: 0.02333706058561802, avg_reward: -0.09850042313337326, memory_size: 8000, batch_size: 64
<Train---------------> [20230722-093016] [INFO]: Model saved to Checkpoints/20230722-084728//model_it23000.pth at iteration 23000
<Train---------------> [20230722-093110] [INFO]: Saving memory...
<Train---------------> [20230722-093117] [INFO]: Iteration 23500, loss: -0.009569206275045872, avg_reward: -0.25378894805908203, memory_size: 8000, batch_size: 64
<Train---------------> [20230722-093203] [INFO]: Training End...
