{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Tuple\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from Agents.A2CAgent import A2CAgent\n",
    "import yaml\n",
    "from TrainUtils import *\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from Models.ModelUtils import *\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "import cv2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MemoryDataset(Dataset):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \"\"\"\n",
    "    dataset directory structure:\n",
    "    YYYYMMDD-HHMMSS\n",
    "        - 1\n",
    "            - 00000.pt\n",
    "            - 00001.pt\n",
    "            - ...\n",
    "        - 2\n",
    "        - ...\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, memory_dirs: List[str]):\n",
    "        self.memory_dirs = memory_dirs\n",
    "\n",
    "        self.file_paths = []\n",
    "        for memory_dir in memory_dirs:\n",
    "            for checkpoint_dir in os.listdir(memory_dir):\n",
    "                checkpoint_path = os.path.join(memory_dir, checkpoint_dir)\n",
    "                for memory_file in os.listdir(checkpoint_path):\n",
    "                    memory_path = os.path.join(checkpoint_path, memory_file)\n",
    "                    self.file_paths.append(memory_path)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def getSaftyMap(self, lidar_map):\n",
    "        blur_map = lidar_map[:, 2, ...].unsqueeze(1)  # (B, 1, 127, 127)\n",
    "        blur_map = blur_map * (blur_map > 0.2)\n",
    "        blur_map = torch.nn.functional.max_pool2d(blur_map, kernel_size=5, stride=1, padding=2)\n",
    "        blur_map = torch.nn.functional.max_pool2d(blur_map, kernel_size=5, stride=1, padding=2)\n",
    "        safety_map = torch.ones(1, 5, 127, 127, dtype=torch.float32, device=blur_map.device)\n",
    "        safety_map[:, 1, ...] = safety_map[:, 1, ...] * (blur_map < 0.1)  # green means absolutely safe\n",
    "        safety_map[:, 0, ...] = safety_map[:, 0, ...] * (blur_map > 0.1) * (blur_map < 0.4)  # blue means not suggested\n",
    "        safety_map[:, 2, ...] = safety_map[:, 2, ...] * (blur_map > 0.4)  # red means dangerous\n",
    "        safety_map[:, 3, ...] = lidar_map[:, 0, ...].unsqueeze(1)  # channel 3 means the target\n",
    "        safety_map[:, 4, ...] = lidar_map[:, 1, ...].unsqueeze(1)  # channel 4 means the start\n",
    "\n",
    "        return safety_map\n",
    "\n",
    "\n",
    "    def getGridWorld(self, safty_map):\n",
    "        # grid_world, blue: wall, green: target, red: start\n",
    "        grid_world = func.max_pool2d(safty_map[:, 2], kernel_size=4, stride=4, padding=2)\n",
    "\n",
    "        target_loc = torch.argmax(safty_map[:, 3].flatten(1), dim=1, keepdim=True)\n",
    "        target_rows = target_loc // 127 // 4\n",
    "        target_cols = target_loc % 127 // 4\n",
    "        end = torch.zeros((grid_world.shape[0], 32, 32), dtype=torch.float32, device=grid_world.device)\n",
    "        # compute the distance from every pixel to the target\n",
    "        h_dist_map = torch.abs(torch.arange(32, dtype=torch.float32, device=grid_world.device).unsqueeze(0).repeat(32, 1) - target_cols)\n",
    "        v_dist_map = torch.abs(torch.arange(32, dtype=torch.float32, device=grid_world.device).unsqueeze(1).repeat(1, 32) - target_rows)\n",
    "        dist_map = torch.sqrt(h_dist_map ** 2 + v_dist_map ** 2).unsqueeze(0).repeat(grid_world.shape[0], 1, 1)\n",
    "        end = 1 - dist_map / torch.max(dist_map.flatten(0), dim=0).values.view(-1, 1, 1)\n",
    "        # cv2.imshow(\"dist_map\", end[0].cpu().numpy())\n",
    "        # cv2.waitKey(0)\n",
    "\n",
    "        start = torch.zeros((grid_world.shape[0], 32, 32), dtype=torch.float32, device=grid_world.device)\n",
    "        start[:, 16, 16] = 1\n",
    "        return torch.stack([end, start, grid_world], dim=1)\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx) -> torch.Tensor:\n",
    "        state: VehicleState = torch.load(self.file_paths[idx])[0]\n",
    "\n",
    "        lidar_map, _ = state.getTensor()    # lidar_map: (1, 3, 127, 127)\n",
    "        safety_map = self.getSaftyMap(lidar_map)  # (1, 5, 127, 127)\n",
    "        grid_world = self.getGridWorld(safety_map)\n",
    "\n",
    "        return lidar_map, safety_map, grid_world\n",
    "\n",
    "\n",
    "def collectFunc(batch: List[torch.Tensor]) -> List[Tensor]:\n",
    "    return batch[0]  # (batch_size, 3, 127, 127)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A* Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPathAStar(grid_world, obstacle_map, start_pos, end_pos, value_map):\n",
    "    # run A* algorithm\n",
    "    path = [start_pos]\n",
    "    path_map = torch.zeros_like(obstacle_map)\n",
    "    path_map[end_pos[0], end_pos[1]] = 0.2\n",
    "    path_map[start_pos[0], start_pos[1]] = 1\n",
    "\n",
    "    while path[-1] != end_pos:\n",
    "        current_r, current_c = path[-1]\n",
    "        best_neighbor = None\n",
    "        best_value = -1\n",
    "        for dr, dc in [(0, 1), (0, -1), (1, 0), (-1, 0)]:\n",
    "            neighbor_r = current_r + dr\n",
    "            neighbor_c = current_c + dc\n",
    "            if 0 <= neighbor_r < 34 and 0 <= neighbor_c < 34 and obstacle_map[neighbor_r, neighbor_c] == 0:\n",
    "                value = value_map[neighbor_r, neighbor_c]\n",
    "                if value > best_value:\n",
    "                    best_value = value\n",
    "                    best_neighbor = [neighbor_r, neighbor_c]\n",
    "        path.append(best_neighbor)\n",
    "        path_map[current_r, current_c] = 0.5\n",
    "        path_map[best_neighbor[0], best_neighbor[1]] = 1\n",
    "        # update value map\n",
    "        value_map[current_r, current_c] -= 1 / 16\n",
    "\n",
    "        grid_world_np = grid_world[0].permute(1, 2, 0).detach().cpu().numpy()\n",
    "        cv2.imshow(\"grid_world\", cv2.resize(grid_world_np, (512, 512), interpolation=cv2.INTER_NEAREST))\n",
    "        cv2.imshow(\"path_map\", cv2.resize(path_map.cpu().numpy(), (512, 512), interpolation=cv2.INTER_NEAREST))\n",
    "        cv2.waitKey(0)\n",
    "\n",
    "    return path"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smooth Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smoothPath(path, obstacle_map):\n",
    "    # shorten path, if two non-adjacent path points are connected by a straight line,\n",
    "    # replace all middle points by a straight line\n",
    "    if len(path) < 3:\n",
    "        return path\n",
    "\n",
    "    i = 0\n",
    "    while (i < len(path) - 2):\n",
    "        # find the last connectable point from path[i]\n",
    "        should_replace = False\n",
    "        replace_id = -1\n",
    "        longest_linkage = []\n",
    "        for j in range(i+2, len(path)):\n",
    "            ri, ci = path[i]\n",
    "            rj, cj = path[j]\n",
    "            dr = rj - ri\n",
    "            dc = cj - ci\n",
    "            l1_dist = abs(dr) + abs(dc)\n",
    "\n",
    "            linkage = [[ri, ci]]\n",
    "            linkage_exist = True\n",
    "            while linkage[-1] != [rj, cj]:\n",
    "                moveable = False\n",
    "                if linkage[-1][0] != rj and obstacle_map[linkage[-1][0]+np.sign(dr), linkage[-1][1]] == 0:\n",
    "                    linkage.append([linkage[-1][0]+np.sign(dr), linkage[-1][1]])\n",
    "                    moveable = True\n",
    "                if linkage[-1][1] != cj and obstacle_map[linkage[-1][0], linkage[-1][1]+np.sign(dc)] == 0:\n",
    "                    linkage.append([linkage[-1][0], linkage[-1][1]+np.sign(dc)])\n",
    "                    moveable = True\n",
    "                if not moveable:\n",
    "                    linkage_exist = False\n",
    "                    break\n",
    "\n",
    "            if j - i > l1_dist and linkage_exist:\n",
    "                longest_linkage = linkage[:]\n",
    "                should_replace = True\n",
    "                replace_id = j\n",
    "\n",
    "        if should_replace:\n",
    "            # now, replace path[i+1] to path[replace_id-1] by a straight line connecting path[i] and path[replace_id]\n",
    "            path = path[:i+1] + longest_linkage + path[replace_id:]\n",
    "            i = replace_id\n",
    "        else:\n",
    "            i += 1\n",
    "\n",
    "    return path"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Path finder\n",
    "Combine above functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findPathTraditional(grid_world):\n",
    "    # grid_world: (1, 3, 32, 32)\n",
    "    # channel 0: end\n",
    "    # channel 1: start\n",
    "    # channel 2: obstacle\n",
    "\n",
    "    grid_world = func.pad(grid_world, (1, 1, 1, 1), mode=\"constant\", value=0)\n",
    "\n",
    "    # run path finding algorithm\n",
    "    obstacle_map = grid_world[0, 2]     # 32x32\n",
    "    value_map = grid_world[0, 0]    # 32x32\n",
    "\n",
    "    start_pos = [17, 17]\n",
    "    end_pos = [int(each) for each in torch.where(grid_world[0, 0] == 1)]\n",
    "    # end_pos.reverse()\n",
    "\n",
    "    path = getPathAStar(grid_world, obstacle_map, start_pos, end_pos, value_map)\n",
    "\n",
    "    path = smoothPath(path, obstacle_map)\n",
    "\n",
    "    grid_world_np = grid_world[0].permute(1, 2, 0).detach().cpu().numpy()\n",
    "    for r, c in path:\n",
    "        grid_world_np[r, c, 1] = 1\n",
    "    cv2.imshow(\"grid_world\", cv2.resize(grid_world_np, (512, 512), interpolation=cv2.INTER_NEAREST))\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "    return path"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with open(\"config_with_mem.yaml\", 'r') as in_file:\n",
    "        configs = yaml.load(in_file, Loader=yaml.FullLoader)\n",
    "\n",
    "    dataset = MemoryDataset(configs[\"data_folders\"])\n",
    "\n",
    "    lidar_map, safety_map, grid_world = dataset[600]\n",
    "    cv2.imshow(\"lidar\", lidar_map[0].cpu().permute(1, 2, 0).numpy())\n",
    "    cv2.imshow(\"safety\", safety_map[0, :3].cpu().permute(1, 2, 0).numpy())\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "    findPathTraditional(grid_world)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
