> Successfully implemented HumanAgent, during training, I can now have control of the vehicle,
> if I did this, the vehicle in the environment will follow my order, instead of obtaining the
> action from the policy network or random action.

> DQNAgent will be too unstable, I will use A2CAgent or PPOAgent instead. However, I am having
> difficulty in storing old policy, $pi_{old}(a|s)$.

> Now the camera (spectator) can follow the ego vehicle

> Now other vehicles can move